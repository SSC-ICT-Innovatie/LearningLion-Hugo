---
authors: Lara Mutsaers
date: 2024-10-10
linktitle: Hoe toets je verantwoorde AI?
title: Hoe toets je verantwoorde AI?
weight: 10
tags: [
    "verantwoorde AI",
    "risico-analyse",
]
---

Wat betekent verantwoorde AI eigenlijk? Voor de overheid betekent dat:
1.	De overheid voldoet aan bestaande wet- en regelgeving;
2.	Voorafgaand aan het gebruik van AI per casus een risico-analyse wordt uitgevoerd. Dit zijn een Data Protection Impact Assessment (DPIA) en een algoritme impact assessment zoals een Impact Assessment Mensenrechten en Algoritmes (IAMA). Daarmee worden de risico’s en risicobeperkende maatregelen vastgesteld;
3.	De uitkomsten van de DPIA ter advies worden voorgelegd aan de Chief Information Officer (CIO) en de Functionaris Gegevensbescherming (FG). 

De bovengenoemde punten zijn ook van toepassing bij het gebruiken of (door)ontwikkelen van een open source generatieve AI-toepassing.

## Wat is een DPIA?

Als het algoritme persoonsgegevens verwerkt, moet er een DPIA worden uitgevoerd. Dit is een instrument om vooraf privacy risico’s van een gegevensverwerking in kaart te brengen. Zo kunnen er maatregelen worden genomen om deze risico’s te verkleinen. Bij het uitvoeren van een DPIA moet onder meer worden geïdentificeerd wat de doelen zijn van de verwerking van de gegevens. Deze moeten ook relevant zijn voor de keuzes rondom de inzet van het algoritme. 

De uitkomsten van het DPIA moeten verplicht worden gedeeld met de Functionaris Gegevensbescherming (FG) om advies te vragen over de uitkomsten. 

## Wat is een IAMA?

Dit impact assessment is een instrument voor discussie en besluitvorming binnen de overheid. Het maakt een dialoog mogelijk tussen verschillende disciplines en stakeholders die betrokken zijn bij de ontwikkeling of inzet van een algoritmisch systeem. Het bevat veel vragen die discussie oproepen met als doel om ervoor te zorgen dat alle relevante aandachtspunten rondom de inzet van een algoritme in een vroegtijdig stadium en op een gestructureerde manier aan bod komen. Hierdoor worden negatieve consequenties tegengegaan die kunnen optreden als er te snel een algoritme wordt ingezet. 

De vragen van de IAMA moeten worden beantwoord als een overheidsorgaan overweegt een algoritme te (laten) ontwikkelen, in te kopen, aan te passen en/of in te gaan zetten. Daarnaast kan het dienen als reflectie.

Het IAMA vind zijn grondslag in een groot aantal richtsnoeren en handreikingen. Twee voorbeelden zijn het Ethische Richtsnoeren voor betrouwbare Kunstmatige Intelligentie en Handreiking non-discriminatie by design. 

Vragen die in het IAMA voorkomen hebben onder andere te maken met het doel van het algoritme, publieke waarden, wettelijke grondslag, verantwoordelijkheden, betrouwbaarheid en mensenrechten. Alle ingrediënten om te voldoen aan de vereisten voor een verantwoorde AI. 

## Referenties

[Overheidsbrede visie Generatieve AI](https://open.overheid.nl/documenten/9aa7b64a-be51-4e6a-ad34-26050b8a67ef/file)

[Voorlopig standpunt generatieve AI kabinet - Digitale Overheid](https://www.digitaleoverheid.nl/nieuws/voorlopig-standpunt-generatieve-ai-kabinet/)

[IAMA](https://open.overheid.nl/documenten/ronl-c3d7fe94-9c62-493f-b858-f56b5e246a94/pdf)

[Ethische richtsnoeren voor betrouwbare KI](https://op.europa.eu/nl/publication-detail/-/publication/d3988569-0434-11ea-8c1f-01aa75ed71a1)

[Non-discriminatie by desing](https://www.tweedekamer.nl/downloads/document?id=2021D22772)

[Data protection impact assessment](https://autoriteitpersoonsgegevens.nl/themas/basis-avg/praktisch-avg/data-protection-impact-assessment-dpia)
                                                   

---
bookFlatSection: true
title: "AI-verordening (EU AI Act)"
---

# AI-verordening (EU AI Act) en LearningLion

Onlangs is de [AI-verordening (EU AI Act)](https://www.europarl.europa.eu/topics/nl/article/20230601STO93804/ai-verordening-eerste-regels-voor-artificiele-intelligentie) gefaseerd van kracht gegaan. Deze omvat eisen en kaders voor de ontwikkeling en het gebruik van AI-systemen door onder andere de overheid. Het doel is om ervoor te zorgen dat innovatie de ruimte krijgt, maar dat dat gebeurt op een veilige, transparante, traceerbare, niet-discriminerende en milieuvriendelijke manier. AI systemen mogen daarnaast nooit volledig geautomatiseerd zijn.

De nieuwe regels die in de AI-verordening staan, houden bepaalde verplichtingen voor aanbieders en gebruikers in, afhankelijk van het risico van de AI-toepassing. Bij veel AI-systemen is het risico minimaal, maar toch moeten ook die worden beoordeeld. Er wordt onderscheid gemaakt in vier risiconiveaus: onaanvaardbaar risico, hoog risico, beperkt risico en laag risico. Generatieve AI wordt niet als hoog risico geclassificeerd, maar moet wel voldoen aan transparantievereisten en het auteursrecht van de EU. Deze regels zijn geldig twaalf maanden na inwerkingtreding:

- De toepassing moet de vermelding bevatten dat de inhoud is gegenereerd door AI.
- Het model moet zodanig worden ontworpen dat er geen illegale inhoud kan worden gegenereerd.
- Er moet een overzicht worden gegeven van auteursrechtelijk beschermde gegevens die voor het trainen van het systeem zijn gebruikt.

AI-modellen met een grote impact die een systeemrisico kunnen vormen, moeten grondig worden geëvalueerd en alle ernstige incidenten moeten worden gemeld aan de Europese Commissie.

## Hoe is de AI-verordening toepasbaar op LearningLion?
Totdat LearningLion als dienst wordt aangeboden, is de AI-verordening waarschijnlijk niet van toepassing. AI-modellen die alleen dienen voor wetenschappelijk onderzoek en -ontwikkeling zijn uitgesloten van de verordening. 

Zodra LearningLion als dienst aangeboden wordt, zijn wij enerzijds een “aanbieder”: een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merk, al dan niet tegen betaling”. Als we het systeem daarnaast zelf zullen gebruiken zijn we anderzijds een “gebruiksverantwoordelijke”: “een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem onder eigen verantwoordelijkheid gebruikt, tenzij het AI-systeem wordt gebruikt in het kader van een persoonlijke niet-beroepsactiviteit”.

LearningLion valt niet onder de verboden AI-praktijken. Ook valt LearningLion in de huidige vorm niet binnen de classificatie van hoog-risico AI-systemen. Omdat LearningLion een generatieve component heeft en gebruikmaakt van bestaande Large Language models (LLM’s) wordt het gezien als een AI-systeem voor algemene doeleinden. Daarom moet het systeem voldoen aan de bijbehorende verplichtingen. Dit zijn:

- De technische documentatie van het model opstellen en up-to-date houden, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt;	
- Informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren. Deze documentatie moet voldoen aan bepaalde eisen (te lezen in de AI-verordening);
- Beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten;
- Een gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content volgens een verplicht template.

Omdat LearningLion interacteert met mensen en synthetische data genereert, in dit geval tekst, moet het daarnaast ook voldoen aan transparantieverplichtingen:

- Het moet te allen tijde duidelijk zijn dat het gaat om een AI-systeem.
- Informeer waar passend en relevant over welke functies het AI-systeem mogelijk maakt, of er menselijk toezicht is, wie er verantwoordelijk is voor de besluitvorming en welke rechten er zijn om bezwaar te maken of verhaal te halen.
- De output van het AI-systeem (de gegenereerde content) moet leesbaar zijn voor een computer en detecteerbaar als gegenereerd met AI of gemanipuleerd.

Deze classificatie is gebaseerd op de [compliance checker](https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/) van de website EU Artificial Intelligence Act. Momenteel werkt de Rijksoverheid om duidelijkheid te creëren over de definities en classificaties uit de wet. Er komen randvoorwaarden voor een goede nationale implementatie van deze wet. 

## Referenties

[Reactie staatssecretaris BZK op het rapport Focus op AI bij de rijksoverheid](https://www.rekenkamer.nl/publicaties/brieven/2024/10/16/reactie-staatssecretaris-van-bzk-op-het-rapport-focus-op-ai-bij-de-rijksoverheid)

[AI-verordening aangenomen door het Europees Parlement](https://www.digitaleoverheid.nl/nieuws/ai-verordening-aangenomen-door-het-europees-parlement/)

[AI-verordening: eerste regels voor artificiële intelligentie](https://www.europarl.europa.eu/topics/nl/article/20230601STO93804/ai-verordening-eerste-regels-voor-artificiele-intelligentie)

[AI-verordening](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2093-1-1)

[Compliance checker](https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/)
